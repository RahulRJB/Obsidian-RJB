
# RCNN


DATE:  04-09-24


Tags: [[Object Detection]]


# References:
- https://www.youtube.com/watch?v=nJzQDpppFj0
- 


# Content:

- [[CNN]] goal: Predict output in an image.
- Object detection models: Predict output in an image + bounding boxes.
- #### Idea of Bounding Boxes:
	- The CNN bit used ![[Attachments/Pasted image 20240904135328.png]]
	- For object detection task we have to modify it a little bit. After fully connected layer, we create 2 branches, 1st for CNN classification, and 2nd another fully connected layer to Output our bounding box coordinates. We already know what are the correct bounding boxes during training, use [[Notes/L2 loss (MSE loss)]]for the loss function(since its regression task). Lastly we use weighted sum of the losses to compute our final loss.![[Attachments/Pasted image 20240904135559.png]]
	- Disadvantage: Only can detect 1 object in the picture because we just output one single bounding box coordinates. Can't use this architecture in scenarios when multiple objects exist in our input. This architecture is just used for **object localization**, i.e. only 1 object in the image.

- #### Idea of Object Detection model:
	- ![[Attachments/Pasted image 20240911123128.png]]In an input image, we define a so-called sliding window. Start with putting it at the top-left corner of the image, then classify the region. So it extracts the region, passes it through a neural network classifier, i.e CNN modules and it produces C+1 output. **C**, num of classes we already know, and 1 for background. In above scenario, since it's the sky without anything so we expect our CNN modules to give us a background class.

	- ![[Attachments/Pasted image 20240911123234.png]]Then we slide our sliding window to every possible locations in the image, eg. here it extracts the region where there's a mountain in it.
	- ![[Attachments/Pasted image 20240911123413.png]] Finally we might reach a region with a car, extract it and classify it.
	- ![[Attachments/Pasted image 20240911123510.png]]**Problem with this model**: Imagine our bounding box has a width *w* and height *h* and image width is *W* and height is *H*. Then possible positions it has to try is `(W-w+1)*(H-h+1)`, which is a lot! Actually it is even worse, the bounding box width and height can change as we slide and that's just because we have to take different boundary boxes with different scales and different aspect ratios into accounts and when we do this, the total possibilities of bounding boxes is insane![[Attachments/Pasted image 20240911123620.png]]For example if the input image is 224x224,  then we have to examine around 635 million boxes which is not computationally feasible if you want to do this in real time.

- #### Idea of RCNN:
	- To tackle the above problem, instead of exploring every possible bounding boxes we can use an external algorithm to propose us some regions. The algorithm used is called [[Selective Search]] which has existed before! 
	- ![[Attachments/Pasted image 20240911124014.png]]Eg. Given above image, the Selective search algo might propose ~2000 bounding boxes that we call region proposals (ROI). The latency for this maybe 1-2seconds.
	- ![[Attachments/Pasted image 20240911124126.png]]So the pipeline is like first we take an image, we run **Selective Search** and it generates some region proposals (ROI). For the sake of simplicity let's assume we have only 2 ROIs. Next we extract these region proposals from the original image, transform them to be all squared and suitable for inputting to a CNN module and produces a class probability for the object in the region.
	- Is it enough, actually not because the bounding box generated by **Selective Search** algorithm may not be precise. For eg. the sleeves of the person above or ears of the horse is missing. So we add another branch that is responsible to tweak the bounding box a little bit and make it better!
	- ![[Attachments/Pasted image 20240911124754.png]]How this work? Our Selective Search algorithm gives us a region proposal described by px, py, ph and pw and our final output of our neural network generates a transform Vector tx, ty, th and tw such as to get the final bb, bx, by, bh and bw using above transformations, translation and log space scale transfer.
	- ![[Attachments/Pasted image 20240911125236.png]]you might wonder what if we output two

boxes both pointing to the same object

Non-max Suppression

for solving this issue non-maximal

suppression which is also called non-max

suppression is proposed note that since

its supervised learning task we already

know what's the perfect bounding box is

and we manually label it before training

the model and we call it grounds truth

and imagine our model gives us these two

bounding boxes both pointing to the same

person

our question here is which one we should

choose

intuitively the one that is closer to

the ground rules and has more

overlapping is a better candidate

so let's formalize this idea and use it

to get the best option 

- ![[Attachments/Pasted image 20240911125358.png]]the Criterion we use to measure

overlapping is called intersection over

Union

let's first understand how this works by

examining ground truths and this

prediction

first we compute the intersection and

let's imagine it's 12.

then we compute the union and then we

divide these two numbers for the other

prediction we do the same computation

Computing intersection Computing Union

and dividing these two numbers now we

have to decide which one is larger the

left IOU is 0.15 and the right one is

0.48

so we say the right one is having more

overlap and we choose this and remove

the left one

- ![[Attachments/Pasted image 20240911125621.png]]ote we use not Max

suppression when the object is the same

for all of the bounding boxes

to give you a better idea of what this

means let's imagine we have this image

and these two bounding boxes

even though they overlap they are

referring to different objects and we

shouldn't apply non-mex suppression in

this scenario
- ![[Attachments/Pasted image 20240911125921.png]] next thing we have to understand is

how to evaluate our model the metric

proposed in the context of object

detection is called mean average

Mean Average Precision

Precision or map

let's imagine we have this beautiful

block picture

we already manually labeled this ground

rules bounding boxes

and our model predicts these three

bounding boxes

the question is which predicted bounding

boxes are correct

to answer this question we take a look

at their IOU

if larger than 0.5 we'll label them as

correct

and otherwise we'll label them as wrong

so while looking at this predicted

bounding boxes

the second one is correct and the rest

are wrong

the metrics we might ask here and are

quite easy are what is precision and

recall

Precision basically means from all our

predictions how many of them are correct

since we predicted three bounding boxes

and only one of them is correct the

Precision would be one-third

and recall means from all the ground

truths how many are we predicted

correctly

there are two ducks and we only

predicted one of them correctly

so recall is one half

- ![[Attachments/Pasted image 20240911130549.png]]now let's understand how Map works it's

a bit difficult compared to these

metrics so be prepared

first let's imagine we have these four

images and their corresponding ground

truth

to calculate the map we first take a

look at only one class and let's choose

the docs first

by giving these pictures to our model

first it predicts some bounding boxes

and each one gives us a probability of

being dog existed in the area

the first step to calculate map is to

sort these bounding boxes based on their

probability score and in the meantime we

consider a diagram called Precision

recall

now we consider the left bounding box

which has the most probability score

does it have an IOU more than 0.5

probably yes so we'll label it as

cracked

and if we remove both the prediction and

ground truth from the image since we

don't care about them anymore

now what's the Precision

so far we only considered one bounding

box and it was true

so it is 1 divided by 1 which is 1. and

what is We call we have total of three

grand truth and one of them is predicted

correctly so far

so it is 1 divided by 3 which is 0.33

and finally we draw our points on our

Precision recall diagram now let's

consider the second Mountain box does it

have audio U of more than 0.5 with any

ground truth no so it is incorrect

and remove it from our image since we

don't care about it anymore

the Precision now would be 0.5 since

half of our prediction is correct so far

but recall stays the same since still we

only predicted one third of our ground

truths scored correctly. nd again we draw our results on the

diagram

for the third rounding box let's assume

it has audio U larger than 0.5 and label

it has cracked

now what's the Precision it is 0.66

since 2 3 of our predictions so far is

correct

and recall is also 0.66 because we

predicted two-thirds of our ground rules

correctly

and again we draw the results on the

diagram

what about the last one

obviously it has all your U Less Than

0.5

so we'll label it as Incorrect and we

remove it from the image again

was the Precision after all it is 0.5

since half of our personal predictions

are correct

and recall is still 0.66 since we

predicted 2 3 of our ground turns

correctly and we draw the final point

and finally we compute the area under

the curve and this gives us average

Precision![[Attachments/Pasted image 20240911130828.png]]


- ![[Attachments/Pasted image 20240911131002.png]]all these calculations were

for dog class which we can assume it

gives us a number such as 0.58 we have

to repeat the same calculation for cat

class and it can give us an average

Precision of like 0.62

then we take average of these two

numbers and it gives us mean average

precision 

- ![[Attachments/Pasted image 20240911131140.png]]too much detail

well actually I'm afraid I have to say

it's even more

because we calculated mean average

Precision where our oil threshold was

0.5

you should try it with other ious such

as

0.55 0.60 and keep continue doing it

until a fixed value such as 0.95

then we take average of all these

numbers and we can say the mean average

Precision is starting from 0.5 until

0.95 with the status of 0.05 is 0.55

man it's a tough metric but it's over


